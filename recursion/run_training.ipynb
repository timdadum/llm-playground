{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab38390",
   "metadata": {},
   "source": [
    "\n",
    "# Playground Training\n",
    "\n",
    "This notebook delegates all logic to the Python modules:\n",
    "- `create_shards.py`\n",
    "- `create_dataloaders.py`\n",
    "- `model.py`\n",
    "- `train.py`\n",
    "\n",
    "Use the cells below to **run** either:\n",
    "- a small **TRM** training/eval run, or\n",
    "- a small **GPT (causal)** training/eval run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a3660c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13\n",
      "PyTorch: 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (Optional) env & versions\n",
    "import sys, torch\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"PyTorch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f027f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNTIME] Device: cpu\n",
      "[MODEL] TRM (iterative refinement).\n",
      "[MODEL] Parameters: 1.62M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8d80461364c8d9b614547604e24e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHARD] Streamed and materialized 100 examples from 'wikimedia/wikipedia' (train).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2df19c6e4d041dfba86a94417a7fc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5150b2eefa4e55afb0208857193abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4020870f3dda46a58e05e1ac352bb4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967254a5257d4c8ea680dfa27e4af520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c1073405ed444ab6b516725e142a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHARD] Saved train split (98 samples) to data\\shards\\train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a509e2198e47fcbd8b30665b8addae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHARD] Saved val split (2 samples) to data\\shards\\val\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1baf84bb147b47d282479ecc743db4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards): 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHARD] Saved test split (0 samples) to data\\shards\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (22847 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] Sample batch: torch.Size([2, 64]) torch.Size([2, 64])\n",
      "[DATA] Sample decode: The alkali metals consist of the chemical elements lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss_avg</td><td>▇▃█▃▂▁▂</td></tr><tr><td>val/loss</td><td>▁</td></tr><tr><td>val/ppl</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss_avg</td><td>10.82291</td></tr><tr><td>val/loss</td><td>21.66598</td></tr><tr><td>val/ppl</td><td>2566948429.55411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fiery-microwave-7</strong> at: <a href='https://wandb.ai/timdadum-personal/llm_playground/runs/y4na3t6v' target=\"_blank\">https://wandb.ai/timdadum-personal/llm_playground/runs/y4na3t6v</a><br> View project at: <a href='https://wandb.ai/timdadum-personal/llm_playground' target=\"_blank\">https://wandb.ai/timdadum-personal/llm_playground</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251101_122510-y4na3t6v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\timda\\Documents\\Repositories\\llm-playground\\recursion\\wandb\\run-20251101_122554-hkcim1wv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/timdadum-personal/llm_playground/runs/hkcim1wv' target=\"_blank\">classic-dew-8</a></strong> to <a href='https://wandb.ai/timdadum-personal/llm_playground' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/timdadum-personal/llm_playground' target=\"_blank\">https://wandb.ai/timdadum-personal/llm_playground</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/timdadum-personal/llm_playground/runs/hkcim1wv' target=\"_blank\">https://wandb.ai/timdadum-personal/llm_playground/runs/hkcim1wv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W&B] Logging enabled.\n",
      "[TRAIN] Epoch 1/1\n",
      "[TRAIN] step 10 | loss 10.8755\n",
      "[TRAIN] step 20 | loss 10.8659\n",
      "[TRAIN] step 30 | loss 10.8661\n",
      "[TRAIN] step 40 | loss 10.8773\n",
      "[TRAIN] step 50 | loss 10.8666\n",
      "[EVAL] step 50 | val_loss 43.4111 | val_ppl 7131857134633034752.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 60 | loss 10.8380\n",
      "[TRAIN] step 70 | loss 10.8418\n",
      "[TRAIN] step 80 | loss 10.8365\n",
      "[TRAIN] step 90 | loss 10.8521\n",
      "[TRAIN] step 100 | loss 10.8337\n",
      "[EVAL] step 100 | val_loss 43.3686 | val_ppl 6835332474107240448.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 110 | loss 10.8350\n",
      "[TRAIN] step 120 | loss 10.8149\n",
      "[TRAIN] step 130 | loss 10.8141\n",
      "[TRAIN] step 140 | loss 10.8416\n",
      "[TRAIN] step 150 | loss 10.8100\n",
      "[EVAL] step 150 | val_loss 43.3249 | val_ppl 6542904150515120128.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 160 | loss 10.7987\n",
      "[TRAIN] step 170 | loss 10.7799\n",
      "[TRAIN] step 180 | loss 10.8074\n",
      "[TRAIN] step 190 | loss 10.8244\n",
      "[TRAIN] step 200 | loss 10.8310\n",
      "[EVAL] step 200 | val_loss 43.2566 | val_ppl 6111101872467935232.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 210 | loss 10.8279\n",
      "[TRAIN] step 220 | loss 10.8215\n",
      "[TRAIN] step 230 | loss 10.8163\n",
      "[TRAIN] step 240 | loss 10.8064\n",
      "[TRAIN] step 250 | loss 10.8006\n",
      "[EVAL] step 250 | val_loss 43.1720 | val_ppl 5615331928623160320.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 260 | loss 10.8004\n",
      "[TRAIN] step 270 | loss 10.7906\n",
      "[TRAIN] step 280 | loss 10.8147\n",
      "[TRAIN] step 290 | loss 10.7625\n",
      "[TRAIN] step 300 | loss 10.7446\n",
      "[EVAL] step 300 | val_loss 43.0460 | val_ppl 4950419786621197312.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 310 | loss 10.7507\n",
      "[TRAIN] step 320 | loss 10.7480\n",
      "[TRAIN] step 330 | loss 10.7341\n",
      "[TRAIN] step 340 | loss 10.7077\n",
      "[TRAIN] step 350 | loss 10.7110\n",
      "[EVAL] step 350 | val_loss 42.8725 | val_ppl 4162020239833581568.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 360 | loss 10.6962\n",
      "[TRAIN] step 370 | loss 10.6868\n",
      "[TRAIN] step 380 | loss 10.7287\n",
      "[TRAIN] step 390 | loss 10.6954\n",
      "[TRAIN] step 400 | loss 10.6859\n",
      "[EVAL] step 400 | val_loss 42.6013 | val_ppl 3173234392556847616.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 410 | loss 10.6713\n",
      "[TRAIN] step 420 | loss 10.6385\n",
      "[TRAIN] step 430 | loss 10.6132\n",
      "[TRAIN] step 440 | loss 10.6256\n",
      "[TRAIN] step 450 | loss 10.7370\n",
      "[EVAL] step 450 | val_loss 42.2611 | val_ppl 2258157125150807552.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 460 | loss 10.5172\n",
      "[TRAIN] step 470 | loss 10.5025\n",
      "[TRAIN] step 480 | loss 10.4540\n",
      "[TRAIN] step 490 | loss 10.4027\n",
      "[TRAIN] step 500 | loss 10.3843\n",
      "[EVAL] step 500 | val_loss 41.7746 | val_ppl 1388337526116379904.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 510 | loss 10.3798\n",
      "[TRAIN] step 520 | loss 10.5016\n",
      "[TRAIN] step 530 | loss 10.3681\n",
      "[TRAIN] step 540 | loss 10.3018\n",
      "[TRAIN] step 550 | loss 10.2076\n",
      "[EVAL] step 550 | val_loss 41.2028 | val_ppl 783705163607281920.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 560 | loss 10.1610\n",
      "[TRAIN] step 570 | loss 10.1739\n",
      "[TRAIN] step 580 | loss 10.1301\n",
      "[TRAIN] step 590 | loss 10.1467\n",
      "[TRAIN] step 600 | loss 10.1149\n",
      "[EVAL] step 600 | val_loss 40.4714 | val_ppl 377153388729870848.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 610 | loss 10.0608\n",
      "[TRAIN] step 620 | loss 9.9125\n",
      "[TRAIN] step 630 | loss 9.9893\n",
      "[TRAIN] step 640 | loss 9.9174\n",
      "[TRAIN] step 650 | loss 9.8212\n",
      "[EVAL] step 650 | val_loss 39.7225 | val_ppl 178353388383657472.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 660 | loss 9.8229\n",
      "[TRAIN] step 670 | loss 9.7343\n",
      "[TRAIN] step 680 | loss 9.6324\n",
      "[TRAIN] step 690 | loss 9.5782\n",
      "[TRAIN] step 700 | loss 9.6981\n",
      "[EVAL] step 700 | val_loss 38.8664 | val_ppl 75764102923662848.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 710 | loss 9.8241\n",
      "[TRAIN] step 720 | loss 9.8172\n",
      "[TRAIN] step 730 | loss 9.4991\n",
      "[TRAIN] step 740 | loss 9.4416\n",
      "[TRAIN] step 750 | loss 9.4173\n",
      "[EVAL] step 750 | val_loss 38.0704 | val_ppl 34179301885266720.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 760 | loss 9.4665\n",
      "[TRAIN] step 770 | loss 9.3944\n",
      "[TRAIN] step 780 | loss 9.3949\n",
      "[TRAIN] step 790 | loss 9.4438\n",
      "[TRAIN] step 800 | loss 9.2348\n",
      "[EVAL] step 800 | val_loss 37.2204 | val_ppl 14609343240851568.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 810 | loss 9.1744\n",
      "[TRAIN] step 820 | loss 9.3561\n",
      "[TRAIN] step 830 | loss 8.8395\n",
      "[TRAIN] step 840 | loss 9.4721\n",
      "[TRAIN] step 850 | loss 9.2293\n",
      "[EVAL] step 850 | val_loss 36.5268 | val_ppl 7301191550697147.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 860 | loss 9.1092\n",
      "[TRAIN] step 870 | loss 9.0503\n",
      "[TRAIN] step 880 | loss 8.9818\n",
      "[TRAIN] step 890 | loss 8.9320\n",
      "[TRAIN] step 900 | loss 8.9963\n",
      "[EVAL] step 900 | val_loss 35.8832 | val_ppl 3836102658622331.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 910 | loss 8.6729\n",
      "[TRAIN] step 920 | loss 8.5141\n",
      "[TRAIN] step 930 | loss 8.5642\n",
      "[TRAIN] step 940 | loss 8.4357\n",
      "[TRAIN] step 950 | loss 8.5821\n",
      "[EVAL] step 950 | val_loss 35.4615 | val_ppl 2516116846976333.50\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 960 | loss 8.7091\n",
      "[TRAIN] step 970 | loss 8.7343\n",
      "[TRAIN] step 980 | loss 8.8668\n",
      "[TRAIN] step 990 | loss 8.8991\n",
      "[TRAIN] step 1000 | loss 8.6789\n",
      "[EVAL] step 1000 | val_loss 35.1920 | val_ppl 1921801342144094.50\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1010 | loss 8.7610\n",
      "[TRAIN] step 1020 | loss 8.3657\n",
      "[TRAIN] step 1030 | loss 8.1990\n",
      "[TRAIN] step 1040 | loss 8.2705\n",
      "[TRAIN] step 1050 | loss 8.3977\n",
      "[EVAL] step 1050 | val_loss 35.0324 | val_ppl 1638260843396745.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1060 | loss 8.4893\n",
      "[TRAIN] step 1070 | loss 8.3892\n",
      "[TRAIN] step 1080 | loss 8.4200\n",
      "[TRAIN] step 1090 | loss 8.5912\n",
      "[TRAIN] step 1100 | loss 8.4621\n",
      "[EVAL] step 1100 | val_loss 34.9458 | val_ppl 1502414459687028.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1110 | loss 8.9511\n",
      "[TRAIN] step 1120 | loss 8.7957\n",
      "[TRAIN] step 1130 | loss 8.6420\n",
      "[TRAIN] step 1140 | loss 9.9037\n",
      "[TRAIN] step 1150 | loss 9.7151\n",
      "[EVAL] step 1150 | val_loss 34.8761 | val_ppl 1401212097936874.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1160 | loss 8.9987\n",
      "[TRAIN] step 1170 | loss 8.7308\n",
      "[TRAIN] step 1180 | loss 8.4727\n",
      "[TRAIN] step 1190 | loss 8.5086\n",
      "[TRAIN] step 1200 | loss 8.6213\n",
      "[EVAL] step 1200 | val_loss 34.8417 | val_ppl 1353856823285576.75\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1210 | loss 8.7378\n",
      "[TRAIN] step 1220 | loss 8.7427\n",
      "[TRAIN] step 1230 | loss 8.6730\n",
      "[TRAIN] step 1240 | loss 8.5756\n",
      "[TRAIN] step 1250 | loss 8.6621\n",
      "[EVAL] step 1250 | val_loss 34.8373 | val_ppl 1347816569254579.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1260 | loss 8.8095\n",
      "[TRAIN] step 1270 | loss 8.7872\n",
      "[TRAIN] step 1280 | loss 8.7206\n",
      "[TRAIN] step 1290 | loss 8.7352\n",
      "[TRAIN] step 1300 | loss 8.6414\n",
      "[EVAL] step 1300 | val_loss 34.7976 | val_ppl 1295418287455569.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1310 | loss 8.6791\n",
      "[TRAIN] step 1320 | loss 8.9995\n",
      "[TRAIN] step 1330 | loss 8.8389\n",
      "[TRAIN] step 1340 | loss 8.8152\n",
      "[TRAIN] step 1350 | loss 8.3329\n",
      "[EVAL] step 1350 | val_loss 34.7701 | val_ppl 1260250617701258.50\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1360 | loss 8.3069\n",
      "[TRAIN] step 1370 | loss 8.3793\n",
      "[TRAIN] step 1380 | loss 8.2855\n",
      "[TRAIN] step 1390 | loss 8.3919\n",
      "[TRAIN] step 1400 | loss 8.6145\n",
      "[EVAL] step 1400 | val_loss 34.7770 | val_ppl 1268947706823617.75\n",
      "[TRAIN] step 1410 | loss 8.7164\n",
      "[TRAIN] step 1420 | loss 8.6150\n",
      "[TRAIN] step 1430 | loss 8.5715\n",
      "[TRAIN] step 1440 | loss 8.3490\n",
      "[TRAIN] step 1450 | loss 8.5535\n",
      "[EVAL] step 1450 | val_loss 34.7530 | val_ppl 1238928650297300.25\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1460 | loss 8.4724\n",
      "[TRAIN] step 1470 | loss 8.1198\n",
      "[TRAIN] step 1480 | loss 8.6055\n",
      "[TRAIN] step 1490 | loss 8.7390\n",
      "[TRAIN] step 1500 | loss 8.8127\n",
      "[EVAL] step 1500 | val_loss 34.7181 | val_ppl 1196427897465477.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1510 | loss 8.6056\n",
      "[TRAIN] step 1520 | loss 8.7536\n",
      "[TRAIN] step 1530 | loss 8.8101\n",
      "[TRAIN] step 1540 | loss 8.6823\n",
      "[TRAIN] step 1550 | loss 8.3540\n",
      "[EVAL] step 1550 | val_loss 34.6885 | val_ppl 1161464220386318.50\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1560 | loss 8.6809\n",
      "[TRAIN] step 1570 | loss 8.5898\n",
      "[TRAIN] step 1580 | loss 8.3914\n",
      "[TRAIN] step 1590 | loss 8.3616\n",
      "[TRAIN] step 1600 | loss 8.2723\n",
      "[EVAL] step 1600 | val_loss 34.6810 | val_ppl 1152845758968083.25\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1610 | loss 8.4122\n",
      "[TRAIN] step 1620 | loss 8.3743\n",
      "[TRAIN] step 1630 | loss 8.3615\n",
      "[TRAIN] step 1640 | loss 8.6315\n",
      "[TRAIN] step 1650 | loss 8.5599\n",
      "[EVAL] step 1650 | val_loss 34.6824 | val_ppl 1154467256318009.50\n",
      "[TRAIN] step 1660 | loss 8.5568\n",
      "[TRAIN] step 1670 | loss 8.5145\n",
      "[TRAIN] step 1680 | loss 8.5037\n",
      "[TRAIN] step 1690 | loss 9.0647\n",
      "[TRAIN] step 1700 | loss 8.5510\n",
      "[EVAL] step 1700 | val_loss 34.6263 | val_ppl 1091451933437335.62\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1710 | loss 8.5584\n",
      "[TRAIN] step 1720 | loss 8.5620\n",
      "[TRAIN] step 1730 | loss 8.6426\n",
      "[TRAIN] step 1740 | loss 8.5954\n",
      "[TRAIN] step 1750 | loss 8.4676\n",
      "[EVAL] step 1750 | val_loss 34.5987 | val_ppl 1061798455635478.88\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1760 | loss 8.5923\n",
      "[TRAIN] step 1770 | loss 8.3975\n",
      "[TRAIN] step 1780 | loss 8.4576\n",
      "[TRAIN] step 1790 | loss 8.6504\n",
      "[TRAIN] step 1800 | loss 8.6218\n",
      "[EVAL] step 1800 | val_loss 34.5829 | val_ppl 1045148534025144.75\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1810 | loss 8.6771\n",
      "[TRAIN] step 1820 | loss 8.6925\n",
      "[TRAIN] step 1830 | loss 8.6108\n",
      "[TRAIN] step 1840 | loss 8.7671\n",
      "[TRAIN] step 1850 | loss 8.7029\n",
      "[EVAL] step 1850 | val_loss 34.5580 | val_ppl 1019396533332596.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1860 | loss 8.6912\n",
      "[TRAIN] step 1870 | loss 8.2189\n",
      "[TRAIN] step 1880 | loss 8.5354\n",
      "[TRAIN] step 1890 | loss 8.4229\n",
      "[TRAIN] step 1900 | loss 8.2806\n",
      "[EVAL] step 1900 | val_loss 34.5540 | val_ppl 1015310792144216.38\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 1910 | loss 8.3421\n",
      "[TRAIN] step 1920 | loss 8.4686\n",
      "[TRAIN] step 1930 | loss 8.4438\n",
      "[TRAIN] step 1940 | loss 8.2908\n",
      "[TRAIN] step 1950 | loss 8.4319\n",
      "[EVAL] step 1950 | val_loss 34.5707 | val_ppl 1032412325357537.75\n",
      "[TRAIN] step 1960 | loss 8.4565\n",
      "[TRAIN] step 1970 | loss 8.3467\n",
      "[TRAIN] step 1980 | loss 8.3994\n",
      "[TRAIN] step 1990 | loss 8.4827\n",
      "[TRAIN] step 2000 | loss 8.4136\n",
      "[EVAL] step 2000 | val_loss 34.5690 | val_ppl 1030703805850138.88\n",
      "[TRAIN] step 2010 | loss 8.4175\n",
      "[TRAIN] step 2020 | loss 8.2076\n",
      "[TRAIN] step 2030 | loss 8.2120\n",
      "[TRAIN] step 2040 | loss 8.3065\n",
      "[TRAIN] step 2050 | loss 8.5360\n",
      "[EVAL] step 2050 | val_loss 34.5653 | val_ppl 1026881930384522.50\n",
      "[TRAIN] step 2060 | loss 8.5659\n",
      "[TRAIN] step 2070 | loss 8.2347\n",
      "[TRAIN] step 2080 | loss 8.5874\n",
      "[TRAIN] step 2090 | loss 8.8905\n",
      "[TRAIN] step 2100 | loss 8.6758\n",
      "[EVAL] step 2100 | val_loss 34.5415 | val_ppl 1002678059178489.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2110 | loss 8.5797\n",
      "[TRAIN] step 2120 | loss 8.5908\n",
      "[TRAIN] step 2130 | loss 8.4327\n",
      "[TRAIN] step 2140 | loss 8.1072\n",
      "[TRAIN] step 2150 | loss 8.3915\n",
      "[EVAL] step 2150 | val_loss 34.5391 | val_ppl 1000307544595338.38\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2160 | loss 8.4055\n",
      "[TRAIN] step 2170 | loss 8.2012\n",
      "[TRAIN] step 2180 | loss 8.4566\n",
      "[TRAIN] step 2190 | loss 8.3230\n",
      "[TRAIN] step 2200 | loss 8.4793\n",
      "[EVAL] step 2200 | val_loss 34.5548 | val_ppl 1016125723775081.88\n",
      "[TRAIN] step 2210 | loss 8.4963\n",
      "[TRAIN] step 2220 | loss 8.5243\n",
      "[TRAIN] step 2230 | loss 8.6291\n",
      "[TRAIN] step 2240 | loss 8.5230\n",
      "[TRAIN] step 2250 | loss 8.4526\n",
      "[EVAL] step 2250 | val_loss 34.5265 | val_ppl 987758155695055.75\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2260 | loss 8.3890\n",
      "[TRAIN] step 2270 | loss 8.2502\n",
      "[TRAIN] step 2280 | loss 8.3440\n",
      "[TRAIN] step 2290 | loss 8.1981\n",
      "[TRAIN] step 2300 | loss 8.3702\n",
      "[EVAL] step 2300 | val_loss 34.5117 | val_ppl 973269571052230.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2310 | loss 8.2003\n",
      "[TRAIN] step 2320 | loss 8.2135\n",
      "[TRAIN] step 2330 | loss 8.5440\n",
      "[TRAIN] step 2340 | loss 8.8165\n",
      "[TRAIN] step 2350 | loss 9.0887\n",
      "[EVAL] step 2350 | val_loss 34.5046 | val_ppl 966402902060042.38\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2360 | loss 8.5347\n",
      "[TRAIN] step 2370 | loss 8.4243\n",
      "[TRAIN] step 2380 | loss 8.2966\n",
      "[TRAIN] step 2390 | loss 8.5736\n",
      "[TRAIN] step 2400 | loss 8.6084\n",
      "[EVAL] step 2400 | val_loss 34.4595 | val_ppl 923798961989970.12\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2410 | loss 8.5032\n",
      "[TRAIN] step 2420 | loss 8.3754\n",
      "[TRAIN] step 2430 | loss 8.5707\n",
      "[TRAIN] step 2440 | loss 8.5682\n",
      "[TRAIN] step 2450 | loss 8.5586\n",
      "[EVAL] step 2450 | val_loss 34.4410 | val_ppl 906890138618877.12\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2460 | loss 8.4995\n",
      "[TRAIN] step 2470 | loss 8.3801\n",
      "[TRAIN] step 2480 | loss 8.3111\n",
      "[TRAIN] step 2490 | loss 8.3169\n",
      "[TRAIN] step 2500 | loss 8.5456\n",
      "[EVAL] step 2500 | val_loss 34.4344 | val_ppl 900875967376140.62\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2510 | loss 8.0671\n",
      "[TRAIN] step 2520 | loss 8.1562\n",
      "[TRAIN] step 2530 | loss 8.2289\n",
      "[TRAIN] step 2540 | loss 8.3309\n",
      "[TRAIN] step 2550 | loss 8.1652\n",
      "[EVAL] step 2550 | val_loss 34.4393 | val_ppl 905269924754555.62\n",
      "[TRAIN] step 2560 | loss 8.2625\n",
      "[TRAIN] step 2570 | loss 8.2864\n",
      "[TRAIN] step 2580 | loss 8.2415\n",
      "[TRAIN] step 2590 | loss 8.2808\n",
      "[TRAIN] step 2600 | loss 8.4065\n",
      "[EVAL] step 2600 | val_loss 34.4043 | val_ppl 874190299791565.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2610 | loss 8.6293\n",
      "[TRAIN] step 2620 | loss 8.5144\n",
      "[TRAIN] step 2630 | loss 8.5732\n",
      "[TRAIN] step 2640 | loss 8.3087\n",
      "[TRAIN] step 2650 | loss 8.5645\n",
      "[EVAL] step 2650 | val_loss 34.3348 | val_ppl 815448142006152.88\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2660 | loss 8.5600\n",
      "[TRAIN] step 2670 | loss 8.4408\n",
      "[TRAIN] step 2680 | loss 8.2239\n",
      "[TRAIN] step 2690 | loss 8.0143\n",
      "[TRAIN] step 2700 | loss 8.2760\n",
      "[EVAL] step 2700 | val_loss 34.2841 | val_ppl 775133698668287.00\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2710 | loss 8.2623\n",
      "[TRAIN] step 2720 | loss 8.2991\n",
      "[TRAIN] step 2730 | loss 8.3471\n",
      "[TRAIN] step 2740 | loss 7.9719\n",
      "[TRAIN] step 2750 | loss 8.5325\n",
      "[EVAL] step 2750 | val_loss 34.3011 | val_ppl 788466439937647.88\n",
      "[TRAIN] step 2760 | loss 7.9664\n",
      "[TRAIN] step 2770 | loss 7.9191\n",
      "[TRAIN] step 2780 | loss 8.0513\n",
      "[TRAIN] step 2790 | loss 8.0219\n",
      "[TRAIN] step 2800 | loss 7.9277\n",
      "[EVAL] step 2800 | val_loss 34.3382 | val_ppl 818222032344640.62\n",
      "[TRAIN] step 2810 | loss 8.4444\n",
      "[TRAIN] step 2820 | loss 8.3366\n",
      "[TRAIN] step 2830 | loss 8.3163\n",
      "[TRAIN] step 2840 | loss 7.9002\n",
      "[TRAIN] step 2850 | loss 7.9923\n",
      "[EVAL] step 2850 | val_loss 34.2610 | val_ppl 757477406267376.62\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2860 | loss 8.3148\n",
      "[TRAIN] step 2870 | loss 8.0335\n",
      "[TRAIN] step 2880 | loss 8.4580\n",
      "[TRAIN] step 2890 | loss 8.1280\n",
      "[TRAIN] step 2900 | loss 8.2066\n",
      "[EVAL] step 2900 | val_loss 34.2033 | val_ppl 715009436782786.25\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2910 | loss 8.4360\n",
      "[TRAIN] step 2920 | loss 8.3388\n",
      "[TRAIN] step 2930 | loss 8.1870\n",
      "[TRAIN] step 2940 | loss 8.1470\n",
      "[TRAIN] step 2950 | loss 8.6789\n",
      "[EVAL] step 2950 | val_loss 34.1450 | val_ppl 674482013963401.38\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 2960 | loss 8.6971\n",
      "[TRAIN] step 2970 | loss 8.3052\n",
      "[TRAIN] step 2980 | loss 8.5920\n",
      "[TRAIN] step 2990 | loss 8.3082\n",
      "[TRAIN] step 3000 | loss 8.5147\n",
      "[EVAL] step 3000 | val_loss 34.0587 | val_ppl 618710413917386.62\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3010 | loss 8.5698\n",
      "[TRAIN] step 3020 | loss 8.1060\n",
      "[TRAIN] step 3030 | loss 8.4797\n",
      "[TRAIN] step 3040 | loss 8.3720\n",
      "[TRAIN] step 3050 | loss 8.1310\n",
      "[EVAL] step 3050 | val_loss 34.0072 | val_ppl 587691199690572.62\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3060 | loss 8.4684\n",
      "[TRAIN] step 3070 | loss 8.3581\n",
      "[TRAIN] step 3080 | loss 8.2354\n",
      "[TRAIN] step 3090 | loss 7.9258\n",
      "[TRAIN] step 3100 | loss 8.4187\n",
      "[EVAL] step 3100 | val_loss 34.0050 | val_ppl 586403452884563.25\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3110 | loss 8.2001\n",
      "[TRAIN] step 3120 | loss 8.3165\n",
      "[TRAIN] step 3130 | loss 8.5069\n",
      "[TRAIN] step 3140 | loss 8.4270\n",
      "[TRAIN] step 3150 | loss 8.3666\n",
      "[EVAL] step 3150 | val_loss 33.9263 | val_ppl 542031252976207.31\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3160 | loss 8.3190\n",
      "[TRAIN] step 3170 | loss 8.1760\n",
      "[TRAIN] step 3180 | loss 8.6417\n",
      "[TRAIN] step 3190 | loss 8.5649\n",
      "[TRAIN] step 3200 | loss 8.2735\n",
      "[EVAL] step 3200 | val_loss 33.8503 | val_ppl 502360987863206.44\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3210 | loss 8.4190\n",
      "[TRAIN] step 3220 | loss 8.2526\n",
      "[TRAIN] step 3230 | loss 8.0802\n",
      "[TRAIN] step 3240 | loss 8.0659\n",
      "[TRAIN] step 3250 | loss 8.0886\n",
      "[EVAL] step 3250 | val_loss 33.8298 | val_ppl 492158724264593.31\n",
      "[CKPT] Saved checkpoint to checkpoints\\checkpoint-best\n",
      "[TRAIN] step 3260 | loss 7.9345\n",
      "[TRAIN] step 3270 | loss 8.2943\n",
      "[TRAIN] step 3280 | loss 8.0988\n",
      "[TRAIN] step 3290 | loss 7.6463\n",
      "[TRAIN] step 3300 | loss 8.0535\n",
      "[EVAL] step 3300 | val_loss 33.9132 | val_ppl 534975765935537.62\n",
      "[TRAIN] step 3310 | loss 8.5948\n",
      "[TRAIN] step 3320 | loss 8.4400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26392\\983842374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_old_argv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\Documents\\Repositories\\llm-playground\\recursion\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    336\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_accum_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                 \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_accum_steps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             )\n\u001b[1;32m--> 521\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     _engine_run_backward(\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\torch\\autograd\\graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\wandb\\integration\\torch\\wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hook_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SHARD_MAX_EXAMPLES = 1000 # to limit data size for test runs\n",
    "argv = [\n",
    "    \"train.py\",\n",
    "    \"--use_trm\",\n",
    "    \"--n\", \"6\",\n",
    "    \"--T\", \"3\",\n",
    "    \"--do_train\",\n",
    "    \"--epochs\", \"1\",\n",
    "    \"--batch_size\", \"2\",\n",
    "    \"--hf_split\", \"train\",\n",
    "    \"--shard_max_examples\", str(SHARD_MAX_EXAMPLES)\n",
    "]\n",
    "\n",
    "from train import main as train_main\n",
    "_old_argv = sys.argv\n",
    "sys.argv = argv\n",
    "try:\n",
    "    train_main()\n",
    "finally:\n",
    "    sys.argv = _old_argv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557e8ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNTIME] Device: cpu\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModelConfig' object has no attribute 'torchscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7292\\2743875860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_old_argv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\Documents\\Repositories\\llm-playground\\recursion\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;31m# Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     model = _build_model(config, \n\u001b[0m\u001b[0;32m    277\u001b[0m                          \u001b[0muse_trm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_trm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                          \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\Documents\\Repositories\\llm-playground\\recursion\\train.py\u001b[0m in \u001b[0;36m_build_model\u001b[1;34m(config, use_trm, n, T, device)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[MODEL] TRM (iterative refinement).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBasicGPT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[MODEL] BasicGPT (causal LM).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mtotal_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\Documents\\Repositories\\llm-playground\\recursion\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# Tie AFTER modules exist (no manual tensor assignment)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtie_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mtie_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1793\u001b[0m             \u001b[0moutput_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_embeddings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1795\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tie_or_clone_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is_encoder_decoder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tie_encoder_decoder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_tie_or_clone_weights\u001b[1;34m(self, output_embeddings, input_embeddings)\u001b[0m\n\u001b[0;32m   1902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_tie_or_clone_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m         \u001b[1;34m\"\"\"Tie or clone module weights depending of whether we are using TorchScript or not\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorchscript\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1905\u001b[0m             \u001b[0moutput_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\timda\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"attribute_map\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"attribute_map\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"attribute_map\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModelConfig' object has no attribute 'torchscript'"
     ]
    }
   ],
   "source": [
    "argv = [\n",
    "    \"train.py\",\n",
    "    \"--do_train\",\n",
    "    \"--epochs\", \"1\",\n",
    "    \"--batch_size\", \"2\",\n",
    "    \"--num_workers\", \"0\",\n",
    "    \"--hf_split\", \"train\",\n",
    "    \"--shard_max_examples\", str(SHARD_MAX_EXAMPLES)\n",
    "]\n",
    "\n",
    "from train import main as train_main\n",
    "_old_argv = sys.argv\n",
    "sys.argv = argv\n",
    "try:\n",
    "    train_main()\n",
    "finally:\n",
    "    sys.argv = _old_argv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
